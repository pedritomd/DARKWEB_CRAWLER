# DarkWeb Crawler v3

Una herramienta avanzada de investigaci√≥n de la web oscura dise√±ada para an√°lisis de amenazas cibern√©ticas e inteligencia de seguridad. Este programa rastrea sitios `.onion` y analiza contenido para detectar actividades il√≠citas, bienes de mercado y posibles amenazas de seguridad.

## ‚ö†Ô∏è Aviso Legal y √âtico

**Este software est√° dise√±ado √∫nicamente para investigaci√≥n de seguridad autorizada.** El usuario asume la responsabilidad total de todas las acciones realizadas con esta herramienta.

- Solo para investigaci√≥n de seguridad autorizada
- Nunca acceda a contenido ilegal
- Respete las leyes locales e internacionales
- La descarga de im√°genes puede constituir infracci√≥n de derechos de autor
- Aseg√∫rese de tener autorizaci√≥n legal antes de usar

## Caracter√≠sticas Principales

- üîç **Rastreo de Profundidad Configurable**: Controle la profundidad y cantidad de p√°ginas a rastrear
- üñºÔ∏è **Captura de Im√°genes**: Descargue y analice im√°genes de sitios rastreados
- üö® **Detecci√≥n de Amenazas**: Identifica palabras clave peligrosas y contenido sospechoso
- üìä **An√°lisis de Mercado**: Categoriza bienes il√≠citos detectados
- üîê **Anonimato Tor**: Utiliza proxy SOCKS5 para mantener anonimato
- üìà **Reportes M√∫ltiples**: Genera reportes en JSON, CSV y texto resumido
- üîÑ **Reinicio de Circuito Tor**: Renueva la identidad Tor peri√≥dicamente
- üìù **Logging Detallado**: Rastreo completo de todas las actividades

## Requisitos Previos

### Software Necesario
- Python 3.7 o superior
- Tor daemon ejecut√°ndose en el puerto 9050
- SOCKS5 proxy accesible

### Dependencias Python
```bash
pip install requests beautifulsoup4 stem lxml pillow nltk
```

### Instalaci√≥n de NLTK Data
El script descargar√° autom√°ticamente los datos de NLTK necesarios (punkt y stopwords) en la primera ejecuci√≥n.

## Instalaci√≥n

1. **Clonar el repositorio**:
```bash
git clone https://github.com/techenthusiast167/DARKWEB_CRAWLER.git
cd DARKWEB_CRAWLER
```

2. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

3. **Verificar Tor**:
```bash
# En otra terminal, aseg√∫rese de que Tor est√© ejecut√°ndose
tor --SocksPort 9050
```

## Uso

### Sintaxis B√°sica
```bash
python dark_crawler.py [OPCIONES]
```

### Opciones de L√≠nea de Comandos

| Opci√≥n | Descripci√≥n |
|--------|------------|
| `-h, --help` | Muestra este mensaje de ayuda |
| `-u URL, --url URL` | URL √∫nica .onion a rastrear |
| `-f FILE, --file FILE` | Archivo con lista de URLs .onion (una por l√≠nea) |
| `-d DEPTH, --depth DEPTH` | Profundidad m√°xima de rastreo (default: 3) |
| `-p PAGES, --pages PAGES` | M√°ximo de p√°ginas por sitio (default: 50) |
| `-o OUTPUT, --output OUTPUT` | Directorio de salida para reportes (default: directorio actual) |
| `--images` | Descargar im√°genes de p√°ginas rastreadas |
| `--images-only` | Descargar SOLO im√°genes, sin an√°lisis de texto |
| `--image-extensions EXT1,EXT2,...` | Extensiones de imagen a descargar |
| `--max-images PER_PAGE` | M√°ximo de im√°genes por p√°gina (default: 10) |
| `--no-tor-check` | Omitir prueba de conexi√≥n Tor |
| `--json` | Generar solo reporte JSON |
| `--csv` | Generar solo reporte CSV |
| `--all` | Generar todos los formatos de reporte |

## Ejemplos de Uso

### 1. Rastreo Simple
```bash
python dark_crawler.py -u http://3g2upl4pq6kufc4m.onion
```

### 2. Rastreo con Captura de Im√°genes
```bash
python dark_crawler.py -u http://marketplace.onion --images
```

### 3. Solo Descargar Im√°genes
```bash
python dark_crawler.py -u http://marketplace.onion --images-only
```

### 4. Rastreo Profundo con Limites Personalizados
```bash
python dark_crawler.py -u http://marketplace.onion --images \
    --image-extensions jpg,png \
    --max-images 5 \
    --depth 4 \
    --pages 100
```

### 5. Rastreo desde Archivo de URLs
```bash
python dark_crawler.py -f urls.txt --all -o ./reportes/
```

### 6. An√°lisis Comprensivo con Todos los Reportes
```bash
python dark_crawler.py -u http://marketplace.onion --images --all -o ./resultados/
```

## Formatos de Salida

### JSON
Archivo: `darkweb_crawl_results.json`

Contiene todos los datos estructurados incluyendo:
- URLs rastreadas
- T√≠tulos y contenido
- Amenazas detectadas
- Bienes de mercado
- Informaci√≥n de im√°genes

```json
{
  "url": "http://example.onion",
  "title": "P√°gina de Ejemplo",
  "threats": {
    "high": ["palabras clave peligrosas"],
    "medium": [],
    "low": []
  },
  "marketplace_goods": {
    "drugs": {"cocaine": 2},
    "weapons": {}
  },
  "images_count": 5
}
```

### CSV
Archivo: `darkweb_crawl_results.csv`

Formato de hoja de c√°lculo con columnas:
- URL
- T√≠tulo
- Contenido
- Amenazas
- Bienes de Mercado
- N√∫mero de Im√°genes
- Archivos de Imagen

### Reporte Resumido
Archivo: `darkweb_analysis_summary.txt`

Resumen textual incluyendo:
- Estad√≠sticas generales
- Desglose de amenazas
- An√°lisis de bienes de mercado
- Top 5 hallazgos de amenazas

### Im√°genes Descargadas
Directorio: `images/`

Archivos de imagen descargados con nombres:
- `image_YYYYMMDD_HHMMSS_HASH.ext`

Manifiesto: `image_manifest.json` (con metadatos de im√°genes)

## Categor√≠as de Amenazas

### Severidad Alta
Terrorismo, tr√°fico de drogas, armas, tr√°fico de personas, pornograf√≠a infantil, fraude de tarjetas de cr√©dito, etc.

### Severidad Media
Drogas, armas, herramientas de hacking, malware, documentos falsos, etc.

### Severidad Baja
Software pirateado, cuentas pirateadas, tutoriales de hacking, etc.

## Categor√≠as de Bienes de Mercado

- **Drogas**: Coca√≠na, hero√≠na, metanfetamina, marijuana, etc.
- **Armas**: Armas de fuego, munici√≥n, explosivos, etc.
- **Bienes Digitales**: Tarjetas de cr√©dito, cuentas, credenciales, malware, etc.
- **Fraude**: Documentos falsos, pasaportes falsos, etc.
- **Servicios**: Hacking, DDoS, phishing, asesinato a sueldo, etc.

## Configuraci√≥n Avanzada

### Personalizar Extensiones de Imagen
```bash
python dark_crawler.py -u http://example.onion \
    --images \
    --image-extensions jpg,png,gif,webp
```

### Limitar Tama√±o de Im√°genes
El tama√±o m√°ximo de imagen est√° limitado a **5 MB** (configurable en el c√≥digo).

### Retraso de Rastreo
El retraso por defecto es **7 segundos** entre solicitudes (configurable).

### Renovar Circuito Tor
Se renueva cada **5 p√°ginas rastreadas** para mayor anonimato.

## Estructura de Carpetas Generada

```
./
‚îú‚îÄ‚îÄ darkweb_crawl_results.json      # Datos JSON completos
‚îú‚îÄ‚îÄ darkweb_crawl_results.csv       # Reporte CSV
‚îú‚îÄ‚îÄ darkweb_analysis_summary.txt    # Resumen textual
‚îú‚îÄ‚îÄ image_manifest.json             # Metadatos de im√°genes
‚îî‚îÄ‚îÄ images/
    ‚îú‚îÄ‚îÄ image_20241215_120000_a1b2c3d4.jpg
    ‚îú‚îÄ‚îÄ image_20241215_120015_e5f6g7h8.png
    ‚îî‚îÄ‚îÄ ...
```

## Interpretaci√≥n de Resultados

### An√°lisis de Amenazas
- **Alto**: Contenido que viola leyes graves
- **Medio**: Actividades sospechosas que merecen investigaci√≥n
- **Bajo**: Contenido potencialmente il√≠cito pero de menor severidad

### An√°lisis de Mercado
Cuenta las menciones de palabras clave de bienes il√≠citos por categor√≠a.

### Metadata de Im√°genes
Cada imagen descargada incluye:
- Nombre de archivo
- Tama√±o en KB
- Dimensiones (ancho x alto)
- Formato
- Hash MD5 (para deduplicaci√≥n)
- URL fuente
- P√°gina de origen

## Notas de Rendimiento

- El rastreo puede ser lento debido a latencias de Tor (esperado)
- Descargar muchas im√°genes aumenta el uso de ancho de banda
- Im√°genes grandes ralentizan el rastreo
- Aumentar la profundidad/p√°ginas aumenta significativamente el tiempo total

## Resoluci√≥n de Problemas

### "Tor connection failed"
```bash
# Aseg√∫rese de que Tor est√© ejecut√°ndose
tor --SocksPort 9050

# Verifique la conectividad
curl -x socks5h://127.0.0.1:9050 http://check.torproject.org/
```

### "No valid .onion URLs provided"
- Verifique que las URLs tengan el formato correcto: `http://XXXXX.onion`
- Verifique que el archivo de URLs no tenga l√≠neas en blanco

### "Failed to download image"
- Puede ser timeout de conexi√≥n
- La imagen podr√≠a ser mayor de 5 MB (l√≠mite configurable)
- El tipo de contenido no es un tipo de imagen v√°lido

### Importaciones Faltantes
```bash
pip install --upgrade requests beautifulsoup4 stem lxml pillow nltk
```

## Constantes Configurables

Edite estas en `dark_crawler.py`:

```python
TOR_SOCKS_PROXY = 'socks5h://127.0.0.1:9050'  # Proxy Tor
TOR_CONTROL_PORT = 9051                        # Puerto de control Tor
DEFAULT_CRAWL_DELAY = 7                        # Retraso entre solicitudes (segundos)
DEFAULT_MAX_DEPTH = 3                          # Profundidad m√°xima
DEFAULT_MAX_PAGES = 50                         # P√°ginas m√°ximas
RETRY_COUNT = 3                                # Reintentos
BACKOFF_FACTOR = 4                             # Factor de retardo exponencial
MAX_IMAGE_SIZE_MB = 5                          # Tama√±o m√°ximo de imagen (MB)
```

## Seguridad y Privacidad

- **Anonimato Tor**: El software utiliza SOCKS5 proxy para todo el tr√°fico
- **Sin Historial Local**: Los datos se guardan en archivos locales
- **Sin Conexi√≥n Directa**: Nunca se conecta directamente (siempre v√≠a Tor)
- **Deduplicaci√≥n de Im√°genes**: Usa hash MD5 para evitar duplicados

## Limitaciones Conocidas

- Algunos sitios bloqueadores de bots pueden no responder
- Sitios con JavaScript din√°mico no se rascrean completamente
- Algunos formatos de imagen no soportados pueden omitirse
- La renovaci√≥n de circuito Tor puede fallar sin puerto de control

## Contribuciones

Para reportar bugs o sugerir mejoras, abra un issue en GitHub.

## Licencia

Ver archivo LICENSE para detalles.

## Autor

**Cyber Threat Intelligence Team**
Versi√≥n: 2.4 (Enhanced with Image Capture & Market Analysis)

---

**√öltima actualizaci√≥n**: Diciembre 2025
